---
layout: post
title: Pytorch笔记(二)
date: 2018-10-03 11:00 +0800
tags: Pytorch, 笔记
---
### Tensor相关
- 以`_`结尾的是inplace方式的函数，会修改调用者自己的数据,e.g.`a.add_(b)`, 加法的结果会存储在`a`中

- `torch.Tensor(*sizes)`创建tensor时，系统不会马上分配空间，只是会计算剩余的内存是否足够，使用tensor的时候才会分配，其他创建tensor的操作都是在创建完tensor之后马上进行分配空间
- `torch.tenosr`是0.4版本新增加的一个新版本的创建tensor方法，使用方法，参数几乎和`np.array`完全一致
- `torch.view`方法可以调整tensor的形状,但必须保证调整前后元素总数一致. 不会修改自身的数据,返回的新tensor与原tensor共享内存。当某个维度为-1时,会自动计算其大小。
- `torch.unsqueeze`增加一个维度
- `torch.squeeze` 把所有维度为1的压缩
- `resize` 是另外一种调整`size`的方法。与`view`不同的是,如果新大小超过了原大小,会自动分配新的内存空间,如果新大小小于原大小,则之前的数据会被保存.
- 通常来讲，索引出来的结果与原tensor共享内存
- `None`类似于`np.newaxis`,新增一个轴
- `gather(input,dim,index)`一个比较复杂的操作,根据index，在`dim`维度上选取数据,输出的`size`与`index`相同
    - e.g. 对一个二维tensor,输出的每个元素如下：
    ```
    out[i][j] = input[index[i][j]][j] #dim=0
    out[i][j] = input[i][index[i][j]] #dim=1
    ```
- `scatter_`与`gathter`相对应的逆操作,`scatter_`把取出的数据放回去,且是`inplace`操作
- 对于只包含一个元素的tensor(与形状无关),使用`tensor.item()`获取标准的对象数值
- 默认的tensor是`FloatTensor`
- `torch.set_default_tensor_type`可以修改默认的tensor类型
- 矩阵的转置会导致存储空间不连续,需要调用`.contiguous`方法将其转为连续
- 当Numpy的数据类型和Tensor的数据类型不一样的时候,数据会被复制,不会共享内存
- 不论输入类型是什么,`torch.tensor`都会进行数据拷贝,不会共享内存
- 广播法则是科学运算中经常使用的一个技巧,它在快速执行向量化操作的同时不会占用额外的内存/显存。Numpy的广播法则定义如下:
    - 让所有输入数组都向其中shape最长的数组看齐,shape中不足的部分通过在前面加1补齐
    - 两个数组要么在某一个维度的长度一致,要么其中一个为1,否则不能计算
    - 当输入数组的某个维度的长度为1时,计算时沿此维度复制扩充成一样的形状
- Pytorch当前已经支持了自动广播法则,但是还是建议通过以下两个函数的组合手动实现广播法则,这样更直观,更不容易出错：
    - `unsqueeze`或者`view`或者tensor[None]:为某一维的形状补1，实现法则1
    - `expand`或者`expand_as`, 重复数组,实现法则3；该操作不会复制数组，所以不会占用额外的空间。
        - 注意，`repeat`实现与`expand`类似的功能，但是`repeat`会把相同数据复制多份，因此会占用额外的空间。
- `expand`不会占用额外空间，只会在需要的时候才扩充，可极大节省内存
- tensor分为信息区和存储区，信息区保存着tensor的形状(size),步长(stride),数据类型(type)等信息，而真正的数据则保存成连续数组。
- 一般来说一个tensor有着与之对应的storage，storage是在data之上封装的接口，便于使用,而不同tensor的头信息一般也不同，但却可能使用相同的数据。
- 绝大多数操作都不修改tensor的数据，而只是修改了tensor的头信息。
- 在使用中需要注意，有些操作会导致tensor不连续，这时需要调用`tensor.contiguous`方法将它们变成连续的数据，该方法会使数据复制一份，不在与原来的数据共享storage。
- 尽量使用`tensor.to(device)`将`device`设置为一个可配置的参数
- 尽量避免频繁的在内存和显存之间传输数据。